---
layout: post
title: Transfer Learning
cover: none.png
date: 2016-10-05 18:09:25 
categories: posts, stream, keras, data, machine learning, autonomous car
---

After last week's troubles, this past stream went over well.  Introducing [transfer learning](http://cs231n.github.io/transfer-learning/), though it hasn't yet produced smashing results, at least worked quickly.  To briefly review, transfer learning is part of an existing model (topology and weights) to kick-start your own model.  In this case, it means using several of the input layers of the [SqueezeNet](https://arxiv.org/abs/1602.07360) architecture to extract interesting image features, and then use those as inputs to the self-driving car model.

<iframe width="560" height="315" src="https://www.youtube.com/embed/qud-WusY7E4" frameborder="0"> </iframe>

So far, the results haven't been stunning.  Off-stream, I trained for about 10 epochs, but the validation accuracy never dropped below 0.02 (and then I ran into some weird memory problem).  This is all with the [DeepDrive](deepdrive.io) data, since that's a bit easier to chew on and I feel has a better mix of turns in the small subset of data I've retained here.

One solution might be to jack up the number of neurons in the dense layer.  This will supply more interesting combinations of the previous convolutional and real valued inputs.  It will also slow down the model, so I need to be careful how far I'm willing to push it.
