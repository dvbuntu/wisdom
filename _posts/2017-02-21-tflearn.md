---
layout: post
title: TensorFlow 1.0 and TFLearn
cover: none.png
date: 2017-02-21 20:01:32 
categories: posts, stream, python, tensorflow, tflearn
---

With the the 1.0 release of [TensorFlow](tensorflow.org), I thought it'd be nice to check out the new high-level interface, TFLearn.  While the old TF included `skflow`, that's been superceded.  I know TFLearn co-existed with it for awhile, but I believe they've now merged or `skflow` was totally subsumed.  Either way, TFLearn is even more abstract than [Keras](keras.io), letting specify a simple neural network in one line.

<iframe width="560" height="315" src="https://www.youtube.com/embed/xRy3ivtnBME" frameborder="0"> </iframe>

While the [basic example](https://www.tensorflow.org/get_started/tflearn) worked flawlessly, I ran into trouble trying to use the slightly more advanced `tf.contrib.learn.DNNLinearCombinedClassifier`.  In such a "wide and deep" model, some of the input features go through a traditional neural network, while others are passed directly to the output later.  Easy enough in concept, right?  And sometimes there's features that you're pretty sure are linear, like certainscale parameters.  But the API for this wasn't very clear, and the [worked example](https://www.tensorflow.org/tutorials/wide_and_deep) only works with [Pandas](http://pandas.pydata.org/) dataframes, not NumPy arrays.  Add to this that it's no longer a "one line model" since it requires a bunch of setup variables and training functions, and it's not so simple.  Using Keras, I'm pretty sure I could do this with a simple Functional Model; not trivial, but reasonably straightforward, and the code would reflect the shape of the "wide and deep" model.  So I'm still sticking to Keras for professional work, but TFLearn is hard to beat for the most common approaches.
